{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-G7hoJQmNQ_",
        "outputId": "e8f88fcb-8edb-486b-e0c0-8c382de25fac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Feb 11 19:16:26 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   58C    P8              13W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Word Tokenization**\n",
        "\n",
        "The NLTK word_tokenize method tokenizes the text into individual words, including contractions like \"I'm\" and emojis like \"ğŸŒâœˆï¸\" treated as separate tokens."
      ],
      "metadata": {
        "id": "4UjbEcbOm_K7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "text = \"As an avid traveler ğŸŒâœˆï¸, I'm constantly seeking new adventures and experiences that broaden my horizons. Whether it's trekking through rugged mountains â›°ï¸, exploring bustling city streets ğŸ™ï¸, or relaxing on pristine beaches ğŸ–ï¸, each journey leaves me with unforgettable memories and valuable lessons. However, amidst the excitement, it's essential to prioritize sustainability and responsible tourism practices. ğŸŒ±ğŸŒ¿ Let's tread lightly on this beautiful planet ğŸŒ, leaving only footprints and taking away memories that last a lifetime. ğŸŒŸâœ¨ Together, let's embrace the spirit of exploration while preserving the wonders of our world for future generations!\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--6T695JmYiA",
        "outputId": "afc5c90b-3a6b-4320-a44d-a760c94623f4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_tokens = nltk.word_tokenize(text)\n",
        "print(word_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ok-3kxSqna_H",
        "outputId": "d9525740-4713-4f26-f923-8c136270838b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['As', 'an', 'avid', 'traveler', 'ğŸŒâœˆï¸', ',', 'I', \"'m\", 'constantly', 'seeking', 'new', 'adventures', 'and', 'experiences', 'that', 'broaden', 'my', 'horizons', '.', 'Whether', 'it', \"'s\", 'trekking', 'through', 'rugged', 'mountains', 'â›°ï¸', ',', 'exploring', 'bustling', 'city', 'streets', 'ğŸ™ï¸', ',', 'or', 'relaxing', 'on', 'pristine', 'beaches', 'ğŸ–ï¸', ',', 'each', 'journey', 'leaves', 'me', 'with', 'unforgettable', 'memories', 'and', 'valuable', 'lessons', '.', 'However', ',', 'amidst', 'the', 'excitement', ',', 'it', \"'s\", 'essential', 'to', 'prioritize', 'sustainability', 'and', 'responsible', 'tourism', 'practices', '.', 'ğŸŒ±ğŸŒ¿', 'Let', \"'s\", 'tread', 'lightly', 'on', 'this', 'beautiful', 'planet', 'ğŸŒ', ',', 'leaving', 'only', 'footprints', 'and', 'taking', 'away', 'memories', 'that', 'last', 'a', 'lifetime', '.', 'ğŸŒŸâœ¨', 'Together', ',', 'let', \"'s\", 'embrace', 'the', 'spirit', 'of', 'exploration', 'while', 'preserving', 'the', 'wonders', 'of', 'our', 'world', 'for', 'future', 'generations', '!']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Sentence Tokenization**\n",
        "\n",
        "The NLTK sent_tokenize method splits the paragraph into individual sentences based on punctuation marks. In this case, there's only one sentence, so it's not very informative for this specific paragraph."
      ],
      "metadata": {
        "id": "SDmB9B4ynlF7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sent_tokens = nltk.sent_tokenize(text)\n",
        "print(sent_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S98Z5dninrMG",
        "outputId": "025f6836-bec6-4e33-d2a3-f8e3b489ad6b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"As an avid traveler ğŸŒâœˆï¸, I'm constantly seeking new adventures and experiences that broaden my horizons.\", \"Whether it's trekking through rugged mountains â›°ï¸, exploring bustling city streets ğŸ™ï¸, or relaxing on pristine beaches ğŸ–ï¸, each journey leaves me with unforgettable memories and valuable lessons.\", \"However, amidst the excitement, it's essential to prioritize sustainability and responsible tourism practices.\", \"ğŸŒ±ğŸŒ¿ Let's tread lightly on this beautiful planet ğŸŒ, leaving only footprints and taking away memories that last a lifetime.\", \"ğŸŒŸâœ¨ Together, let's embrace the spirit of exploration while preserving the wonders of our world for future generations!\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Punctuation-based Tokenizer**\n",
        "\n",
        "The NLTK WordPunctTokenizer splits the text based on punctuation marks, treating them as separate tokens. This tokenizer is useful for extracting words and punctuation separately."
      ],
      "metadata": {
        "id": "HMAvl_YSnvaZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import WordPunctTokenizer\n",
        "tokenizer = WordPunctTokenizer()\n",
        "punct_tokens = tokenizer.tokenize(text)\n",
        "print(punct_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RyfCHmTgny3L",
        "outputId": "44ad9f4a-dac7-43d7-a8f4-d81557bcb241"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['As', 'an', 'avid', 'traveler', 'ğŸŒâœˆï¸,', 'I', \"'\", 'm', 'constantly', 'seeking', 'new', 'adventures', 'and', 'experiences', 'that', 'broaden', 'my', 'horizons', '.', 'Whether', 'it', \"'\", 's', 'trekking', 'through', 'rugged', 'mountains', 'â›°ï¸,', 'exploring', 'bustling', 'city', 'streets', 'ğŸ™ï¸,', 'or', 'relaxing', 'on', 'pristine', 'beaches', 'ğŸ–ï¸,', 'each', 'journey', 'leaves', 'me', 'with', 'unforgettable', 'memories', 'and', 'valuable', 'lessons', '.', 'However', ',', 'amidst', 'the', 'excitement', ',', 'it', \"'\", 's', 'essential', 'to', 'prioritize', 'sustainability', 'and', 'responsible', 'tourism', 'practices', '.', 'ğŸŒ±ğŸŒ¿', 'Let', \"'\", 's', 'tread', 'lightly', 'on', 'this', 'beautiful', 'planet', 'ğŸŒ,', 'leaving', 'only', 'footprints', 'and', 'taking', 'away', 'memories', 'that', 'last', 'a', 'lifetime', '.', 'ğŸŒŸâœ¨', 'Together', ',', 'let', \"'\", 's', 'embrace', 'the', 'spirit', 'of', 'exploration', 'while', 'preserving', 'the', 'wonders', 'of', 'our', 'world', 'for', 'future', 'generations', '!']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Treebank Word tokenizer**\n",
        "\n",
        "The NLTK TreebankWordTokenizer tokenizes the text following the conventions of the Penn Treebank, which handles contractions and punctuation differently. It splits contractions like \"I'm\" into separate tokens \"I\" and \"'m\" and also treats emojis as separate tokens."
      ],
      "metadata": {
        "id": "ukLagZr5n6Jx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import TreebankWordTokenizer\n",
        "tokenizer = TreebankWordTokenizer()\n",
        "treebank_tokens = tokenizer.tokenize(text)\n",
        "print(treebank_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vuGuB074n20-",
        "outputId": "73e7e725-f521-488f-b1c1-446b95c2b467"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['As', 'an', 'avid', 'traveler', 'ğŸŒâœˆï¸', ',', 'I', \"'m\", 'constantly', 'seeking', 'new', 'adventures', 'and', 'experiences', 'that', 'broaden', 'my', 'horizons.', 'Whether', 'it', \"'s\", 'trekking', 'through', 'rugged', 'mountains', 'â›°ï¸', ',', 'exploring', 'bustling', 'city', 'streets', 'ğŸ™ï¸', ',', 'or', 'relaxing', 'on', 'pristine', 'beaches', 'ğŸ–ï¸', ',', 'each', 'journey', 'leaves', 'me', 'with', 'unforgettable', 'memories', 'and', 'valuable', 'lessons.', 'However', ',', 'amidst', 'the', 'excitement', ',', 'it', \"'s\", 'essential', 'to', 'prioritize', 'sustainability', 'and', 'responsible', 'tourism', 'practices.', 'ğŸŒ±ğŸŒ¿', 'Let', \"'s\", 'tread', 'lightly', 'on', 'this', 'beautiful', 'planet', 'ğŸŒ', ',', 'leaving', 'only', 'footprints', 'and', 'taking', 'away', 'memories', 'that', 'last', 'a', 'lifetime.', 'ğŸŒŸâœ¨', 'Together', ',', 'let', \"'s\", 'embrace', 'the', 'spirit', 'of', 'exploration', 'while', 'preserving', 'the', 'wonders', 'of', 'our', 'world', 'for', 'future', 'generations', '!']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Tweet Tokenizer**\n",
        "\n",
        "The NLTK TweetTokenizer is designed specifically for tokenizing tweets, which often contain emojis and hashtags. It tokenizes emojis separately from words and punctuation, treating them as individual tokens."
      ],
      "metadata": {
        "id": "d3oa6sAjoBiM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import TweetTokenizer\n",
        "tokenizer = TweetTokenizer()\n",
        "tweet_tokens = tokenizer.tokenize(text)\n",
        "print(tweet_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "712VtGAcoDUx",
        "outputId": "0c13a05e-dff2-4311-e263-4939dc7f17a9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['As', 'an', 'avid', 'traveler', 'ğŸŒ', 'âœˆ', 'ï¸', ',', \"I'm\", 'constantly', 'seeking', 'new', 'adventures', 'and', 'experiences', 'that', 'broaden', 'my', 'horizons', '.', 'Whether', \"it's\", 'trekking', 'through', 'rugged', 'mountains', 'â›°', 'ï¸', ',', 'exploring', 'bustling', 'city', 'streets', 'ğŸ™', 'ï¸', ',', 'or', 'relaxing', 'on', 'pristine', 'beaches', 'ğŸ–', 'ï¸', ',', 'each', 'journey', 'leaves', 'me', 'with', 'unforgettable', 'memories', 'and', 'valuable', 'lessons', '.', 'However', ',', 'amidst', 'the', 'excitement', ',', \"it's\", 'essential', 'to', 'prioritize', 'sustainability', 'and', 'responsible', 'tourism', 'practices', '.', 'ğŸŒ±', 'ğŸŒ¿', \"Let's\", 'tread', 'lightly', 'on', 'this', 'beautiful', 'planet', 'ğŸŒ', ',', 'leaving', 'only', 'footprints', 'and', 'taking', 'away', 'memories', 'that', 'last', 'a', 'lifetime', '.', 'ğŸŒŸ', 'âœ¨', 'Together', ',', \"let's\", 'embrace', 'the', 'spirit', 'of', 'exploration', 'while', 'preserving', 'the', 'wonders', 'of', 'our', 'world', 'for', 'future', 'generations', '!']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Multi-Word Expression Tokenizer**\n",
        "\n",
        "The NLTK MWETokenizer is used to tokenize multi-word expressions. Since the traveler paragraph doesn't contain specific multi-word expressions, this tokenizer doesn't provide any additional insights here."
      ],
      "metadata": {
        "id": "6AzjaPQpoHAu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import MWETokenizer\n",
        "tokenizer = MWETokenizer()\n",
        "mwe_tokens = tokenizer.tokenize(text.split())\n",
        "print(mwe_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xBUZ5G-FoLLm",
        "outputId": "fad35767-13bc-4e39-bdff-46ac6e92ce51"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['As', 'an', 'avid', 'traveler', 'ğŸŒâœˆï¸,', \"I'm\", 'constantly', 'seeking', 'new', 'adventures', 'and', 'experiences', 'that', 'broaden', 'my', 'horizons.', 'Whether', \"it's\", 'trekking', 'through', 'rugged', 'mountains', 'â›°ï¸,', 'exploring', 'bustling', 'city', 'streets', 'ğŸ™ï¸,', 'or', 'relaxing', 'on', 'pristine', 'beaches', 'ğŸ–ï¸,', 'each', 'journey', 'leaves', 'me', 'with', 'unforgettable', 'memories', 'and', 'valuable', 'lessons.', 'However,', 'amidst', 'the', 'excitement,', \"it's\", 'essential', 'to', 'prioritize', 'sustainability', 'and', 'responsible', 'tourism', 'practices.', 'ğŸŒ±ğŸŒ¿', \"Let's\", 'tread', 'lightly', 'on', 'this', 'beautiful', 'planet', 'ğŸŒ,', 'leaving', 'only', 'footprints', 'and', 'taking', 'away', 'memories', 'that', 'last', 'a', 'lifetime.', 'ğŸŒŸâœ¨', 'Together,', \"let's\", 'embrace', 'the', 'spirit', 'of', 'exploration', 'while', 'preserving', 'the', 'wonders', 'of', 'our', 'world', 'for', 'future', 'generations!']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**TextBlob Word Tokenizer**\n",
        "\n",
        "TextBlob tokenizes the text into words similar to NLTK's word_tokenize, handling contractions and emojis as separate tokens."
      ],
      "metadata": {
        "id": "XPM0nqhhoNVv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "blob = TextBlob(text)\n",
        "textblob_tokens = blob.words\n",
        "print(textblob_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KdylmThZoSSe",
        "outputId": "4cafab7b-448e-4a88-befc-a1b186473e5b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['As', 'an', 'avid', 'traveler', 'ğŸŒâœˆï¸', 'I', \"'m\", 'constantly', 'seeking', 'new', 'adventures', 'and', 'experiences', 'that', 'broaden', 'my', 'horizons', 'Whether', 'it', \"'s\", 'trekking', 'through', 'rugged', 'mountains', 'â›°ï¸', 'exploring', 'bustling', 'city', 'streets', 'ğŸ™ï¸', 'or', 'relaxing', 'on', 'pristine', 'beaches', 'ğŸ–ï¸', 'each', 'journey', 'leaves', 'me', 'with', 'unforgettable', 'memories', 'and', 'valuable', 'lessons', 'However', 'amidst', 'the', 'excitement', 'it', \"'s\", 'essential', 'to', 'prioritize', 'sustainability', 'and', 'responsible', 'tourism', 'practices', 'ğŸŒ±ğŸŒ¿', 'Let', \"'s\", 'tread', 'lightly', 'on', 'this', 'beautiful', 'planet', 'ğŸŒ', 'leaving', 'only', 'footprints', 'and', 'taking', 'away', 'memories', 'that', 'last', 'a', 'lifetime', 'ğŸŒŸâœ¨', 'Together', 'let', \"'s\", 'embrace', 'the', 'spirit', 'of', 'exploration', 'while', 'preserving', 'the', 'wonders', 'of', 'our', 'world', 'for', 'future', 'generations']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**spaCy Tokenizer**\n",
        "\n",
        "spaCy tokenizes the text into words, handling contractions, punctuation, and emojis as separate tokens."
      ],
      "metadata": {
        "id": "rF5uxMVsoUuS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(text)\n",
        "spacy_tokens = [token.text for token in doc]\n",
        "print(spacy_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KhZ0pNUAoYnl",
        "outputId": "1ff78b9b-bda4-49f8-8e90-c38eadd61140"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['As', 'an', 'avid', 'traveler', 'ğŸŒ', 'âœˆ', 'ï¸', ',', 'I', \"'m\", 'constantly', 'seeking', 'new', 'adventures', 'and', 'experiences', 'that', 'broaden', 'my', 'horizons', '.', 'Whether', 'it', \"'s\", 'trekking', 'through', 'rugged', 'mountains', 'â›°', 'ï¸', ',', 'exploring', 'bustling', 'city', 'streets', 'ğŸ™', 'ï¸', ',', 'or', 'relaxing', 'on', 'pristine', 'beaches', 'ğŸ–', 'ï¸', ',', 'each', 'journey', 'leaves', 'me', 'with', 'unforgettable', 'memories', 'and', 'valuable', 'lessons', '.', 'However', ',', 'amidst', 'the', 'excitement', ',', 'it', \"'s\", 'essential', 'to', 'prioritize', 'sustainability', 'and', 'responsible', 'tourism', 'practices', '.', 'ğŸŒ±', 'ğŸŒ¿', 'Let', \"'s\", 'tread', 'lightly', 'on', 'this', 'beautiful', 'planet', 'ğŸŒ', ',', 'leaving', 'only', 'footprints', 'and', 'taking', 'away', 'memories', 'that', 'last', 'a', 'lifetime', '.', 'ğŸŒŸ', 'âœ¨', 'Together', ',', 'let', \"'s\", 'embrace', 'the', 'spirit', 'of', 'exploration', 'while', 'preserving', 'the', 'wonders', 'of', 'our', 'world', 'for', 'future', 'generations', '!']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Gensim word tokenizer**\n",
        "\n",
        "Gensim tokenizes the text into words, treating emojis and punctuation as separate tokens, similar to other word tokenization methods."
      ],
      "metadata": {
        "id": "Yck5bYiCogAz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.utils import tokenize\n",
        "gensim_tokens = list(tokenize(text))\n",
        "print(gensim_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RiEBjIJoofKE",
        "outputId": "c95b4ef6-1e28-4801-9a24-53af16e548a9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['As', 'an', 'avid', 'traveler', 'I', 'm', 'constantly', 'seeking', 'new', 'adventures', 'and', 'experiences', 'that', 'broaden', 'my', 'horizons', 'Whether', 'it', 's', 'trekking', 'through', 'rugged', 'mountains', 'exploring', 'bustling', 'city', 'streets', 'or', 'relaxing', 'on', 'pristine', 'beaches', 'each', 'journey', 'leaves', 'me', 'with', 'unforgettable', 'memories', 'and', 'valuable', 'lessons', 'However', 'amidst', 'the', 'excitement', 'it', 's', 'essential', 'to', 'prioritize', 'sustainability', 'and', 'responsible', 'tourism', 'practices', 'Let', 's', 'tread', 'lightly', 'on', 'this', 'beautiful', 'planet', 'leaving', 'only', 'footprints', 'and', 'taking', 'away', 'memories', 'that', 'last', 'a', 'lifetime', 'Together', 'let', 's', 'embrace', 'the', 'spirit', 'of', 'exploration', 'while', 'preserving', 'the', 'wonders', 'of', 'our', 'world', 'for', 'future', 'generations']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Tokenization with Keras (using Keras Tokenizer)**\n",
        "\n",
        "Keras Tokenizer tokenizes the text into words, treating emojis and punctuation as separate tokens, similar to other word tokenization methods."
      ],
      "metadata": {
        "id": "L-sx1bsWolof"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts([text])\n",
        "keras_tokens = tokenizer.texts_to_sequences([text])\n",
        "print(keras_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AM9yKICrofS2",
        "outputId": "112b68a3-257d-47f9-9098-02e68e1f7f63"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 1, 19, 3, 20, 21, 22, 23, 4, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 5, 36, 37, 38, 39, 40, 41, 42, 43, 44, 6, 1, 45, 46, 47, 48, 2, 49, 4, 50, 51, 52, 53, 1, 54, 55, 56, 57, 7, 58, 59, 5, 60, 61, 62, 63, 64, 65, 66, 1, 67, 68, 6, 3, 69, 70, 71, 72, 73, 7, 74, 2, 75, 8, 76, 77, 78, 2, 79, 8, 80, 81, 82, 83, 84]]\n"
          ]
        }
      ]
    }
  ]
}